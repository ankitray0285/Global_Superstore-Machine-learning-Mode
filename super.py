# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hmkjvuDtG3kZ894A5D0_Psw6t-bHkh4r
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Data Analysis

Dataset Description

Row ID: Unique identification number of the Row

Order ID: Unique identification number of the Order

Order Date: Date of order

Ship Date: Shipping date of order

Ship Mode: Shipping mode of the order

Customer ID: Unique identification number of the customer

Customer Name: Name of the customer

Segment: Segment of market

City: City name where customer lives

State: State name where customer lives

Country: Country name where customer lives

Postal Code: Postal code of the destination

Market: Market from where the product was purchased

Region: Region

Product ID: Unique identification number of the product

Category: Category of the product

Sub-Category: Sub-Category of the product

Product Name: Name of the product

Sales: Amount of sales

Quantity: Quantity of product

Discount: Discount on the product value

Profit: Profit made from the sales

Shipping Cost: Cost of shipping

Order Priority: Proirity of the order

# Tasks to be performed:

Import required libraries and load the dataset

Generate the dataset report using sweetviz

Perform necessary data preprocessing:
Check missing values
Check datatype of columns
Fill missing values with mean, median or 0

Perform Exploratory Data Analysis (EDA) on the dataset
Plot Univariate Distributions
Plot Bi-Variate Distributions

Pre-process that data set for modeling

Handle Missing values present in the dataset

Encode the categorical variables present

Split the data into training and testing set using sklearn's train_test_split function

Modelling

Build and evaluate an Interactive Linear Regression
"""

Global_superstore= pd.read_csv('/content/Global_Superstore2.csv')

Global_superstore.head(5)

Global_superstore.value_counts().sum()

store=Global_superstore

store.info()

store.columns

# Checking for missing values
def check_miss(store):
    '''
    data: requires a DataFrame object.
    ---
    returns: A DataFrame with details about missing values
    '''
    cnull=[sum(store[y].isnull()) for y in store.columns]
    miss=pd.DataFrame({'Null Values':
                        [any(store[x].isnull()) for x in store.columns],
                    'Count_Nulls':cnull,
                    'Percentage_Nulls':list((np.array(cnull)*100)/store.shape[0]),
                    'MValues':cnull,
                    'Dtype':store.dtypes
                      })
    return miss.sort_values(by='MValues',ascending=False)

check_miss(store)

"""# Datatype conversion"""

# Convert data types for optimization
store['Row ID'] = store['Row ID'].astype('int32')
store['Order ID'] = store['Order ID'].astype('category')
store['Order Date'] = pd.to_datetime(store['Order Date'], format='%d-%m-%Y')
store['Ship Date'] = pd.to_datetime(store['Ship Date'], format='%d-%m-%Y')
store['Customer ID'] = store['Customer ID'].astype('category')
store['Customer Name'] = store['Customer Name'].astype('category')
store['Segment'] = store['Segment'].astype('category')
store['City'] = store['City'].astype('category')
store['State'] = store['State'].astype('category')
store['Country'] = store['Country'].astype('category')
store['Market'] = store['Market'].astype('category')
store['Region'] = store['Region'].astype('category')
store['Product ID'] = store['Product ID'].astype('category')
store['Category'] = store['Category'].astype('category')
store['Sub-Category'] = store['Sub-Category'].astype('category')
store['Product Name'] = store['Product Name'].astype('str')
store['Sales'] = store['Sales'].astype('int64')

store

# keeping the original data aside
orig_data=store.copy()

#filling missing
mean_filled_data=store.copy()

mean_filled_data['Shipping Cost'].fillna(mean_filled_data['Shipping Cost'].mean(),inplace=True)
mean_filled_data['Profit'].fillna(mean_filled_data['Profit'].mean(),inplace=True)
mean_filled_data['Discount'].fillna(mean_filled_data['Discount'].mean(),inplace=True)

# Filling with mode as Order Priority is categorical
mean_filled_data['Order Priority'].fillna(mean_filled_data['Order Priority'].mode(),inplace=True)

zero_filled_data=store.copy()

zero_filled_data['Shipping Cost'].fillna(0,inplace=True)
zero_filled_data['Profit'].fillna(0,inplace=True)
zero_filled_data['Discount'].fillna(0,inplace=True)

# Filling with mode as Order Priority is categorical
zero_filled_data['Order Priority'].fillna(zero_filled_data['Order Priority'].mode(),inplace=True)

"""# Exploratory Data Analysis
# Univariate Distributions
"""

# importing required libraries
import plotly.express as px
import plotly.graph_objects as go



import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# Grouping by Market and calculating mean values
shipcst_market = store.groupby('Market').mean(numeric_only=True)

# Extracting market names (index)
markets = shipcst_market.index

# Creating the bar chart
fig = go.Figure(data=[
    go.Bar(name='Sales', x=markets, y=shipcst_market['Sales']),
    go.Bar(name='Quantity', x=markets, y=shipcst_market['Quantity']),
    go.Bar(name='Discount', x=markets, y=shipcst_market['Discount']),
    go.Bar(name='Profit', x=markets, y=shipcst_market['Profit']),
    go.Bar(name='Shipping Cost', x=markets, y=shipcst_market['Shipping Cost'])
])

# Change the bar mode to group
fig.update_layout(
    barmode='group',
    title="Market-wise Average Sales, Quantity, Discount, Profit & Shipping Cost",
    xaxis_title="Markets",
    yaxis_title="Average Values",
    legend_title="Metrics",
)

# Show the figure
fig.show()

"""##        Observations:

APAC has highest sales while canada makes higest profit

EMEA has highest discount but the sales are lowest

Shipping cost in APAC markest is highest while in other markets its lower
"""

# Group by 'Country' and calculate the mean values
country_profit = store.groupby('Country').mean(numeric_only=True)

# Sort by Profit in ascending order
country_profit = country_profit.sort_values(by='Profit')

# Create a bar chart with color intensity based on profit values
fig = px.bar(
    x=country_profit.index,
    y=country_profit['Profit'],
    color=country_profit['Profit'],
    color_continuous_scale=px.colors.sequential.Rainbow,
    height=600,
    width=1000,
    labels={'x': 'Country', 'y': 'Average Profit'},
    title="Country-wise Average Profit"
)

# Show the figure
fig.show()

"""Observations:

Lesotho made highest sale while uganda is at lowest
"""

# Grouping by 'Country' and calculating mean values
country_profit = store.groupby('Country').mean(numeric_only=True)

# Sorting by Profit in ascending order
country_profit = country_profit.sort_values(by='Profit')

# Creating a bar chart
fig = px.bar(
    x=country_profit.index,
    y=country_profit['Profit'],
    color=country_profit['Profit'],
    color_continuous_scale=px.colors.sequential.Rainbow,
    height=600,
    width=1000,
    labels={'x': 'Country', 'y': 'Average Profit'},
    title="Country-wise Average Profit"
)

# Display the figure
fig.show()

"""Obeservations

In Lithuania the sore suffered heaviest loss while in Montenegro store made really good profit

In 29 countries the store suffered loss
"""

# Grouping by 'Country' and calculating mean values
country_sales = store.groupby('Country').mean(numeric_only=True)

# Creating a scatter plot
fig = px.scatter(
    country_sales,
    x="Sales",
    y="Profit",
    size="Shipping Cost",
    color="Discount",
    hover_name=country_sales.index,
    log_x=True,
    size_max=60,
    title="Sales vs Profit (Bubble size: Shipping Cost, Color: Discount)"
)

# Display the figure
fig.show()

"""Observations

If the discount is high there will be loss

For higher sales the shipping cost is also high
"""

# Creating a copy of the dataset
monthly_sales = store.copy()

# Converting 'Order Date' to datetime (if not already)
monthly_sales['Order Date'] = pd.to_datetime(monthly_sales['Order Date'])

# Setting 'Order Date' as index
monthly_sales.set_index('Order Date', inplace=True)

# Aggregating sales by day and then resampling by month
monthly_sales = monthly_sales.resample('M').sum(numeric_only=True)

# Creating a line chart
fig = px.line(
    x=monthly_sales.index,
    y=monthly_sales['Sales'],
    labels={'x': 'Month', 'y': 'Total Sales'},
    title="Monthly Sales Trend"
)

# Display the figure
fig.show()

"""Observations

Every june, september, november and december the sales increase really high

Every july the sales are least in the respective year
"""

#Yearly Analysis
import pandas as pd

# Creating a copy of the dataset
yearly_sales = store.copy()

# Converting 'Order Date' to datetime (if not already)
yearly_sales['Order Date'] = pd.to_datetime(yearly_sales['Order Date'])

# Setting 'Order Date' as index
yearly_sales.set_index('Order Date', inplace=True)

# Resampling to get yearly sales sum
yearly_sales = yearly_sales.resample('Y').sum(numeric_only=True)

# Display the result
print(yearly_sales)

import pandas as pd
import plotly.graph_objects as go

# Converting 'Order Date' index to year format (YYYY)
year = yearly_sales.index.strftime('%Y')

# Creating a grouped bar chart
fig = go.Figure(data=[
    go.Bar(name='Sales', x=year, y=yearly_sales['Sales']),
    go.Bar(name='Quantity', x=year, y=yearly_sales['Quantity']),
    go.Bar(name='Discount', x=year, y=yearly_sales['Discount']),
    go.Bar(name='Profit', x=year, y=yearly_sales['Profit']),
    go.Bar(name='Shipping Cost', x=year, y=yearly_sales['Shipping Cost'])
])

# Change the bar mode to 'group'
fig.update_layout(
    barmode='group',
    title="Yearly Sales, Quantity, Discount, Profit, and Shipping Cost",
    xaxis_title="Year",
    yaxis_title="Total Value",
    legend_title="Metrics"
)

# Display the figure
fig.show()

"""Obeservations

The sales are increasing on yearly basis
"""

import pandas as pd
import plotly.express as px

# Creating a copy of the dataset
weekday = store.copy()

# Converting 'Order Date' to datetime (if not already)
weekday['Order Date'] = pd.to_datetime(weekday['Order Date'])

# Extracting day names
weekday['Day'] = weekday['Order Date'].dt.day_name()

# Aggregating by day
weekday = weekday.groupby('Day').sum(numeric_only=True)

# Sorting by 'Sales'
weekday = weekday.sort_values(by='Sales')

# Creating a scatter plot
fig = px.scatter(
    weekday,
    x="Profit",
    y="Sales",
    size="Shipping Cost",
    color="Discount",
    hover_name=weekday.index,
    log_x=True,
    size_max=60,
    color_continuous_scale=px.colors.cmocean.balance,
    title="Sales vs Profit (Grouped by Weekday)",
    labels={"Sales": "Total Sales", "Profit": "Total Profit", "Discount": "Discount Applied"}
)

# Show the figure
fig.show()

"""Obsevations

Except weekends the sales and profit made is high

Least profit and sales made is on sunday

Highest profit and sales made is on Friday
"""

import pandas as pd
import plotly.express as px

# Function to generate formatted labels (Day_Segment)
def day_segment(x):
    return [str(i[0]) + '_' + str(i[1]) for i in x]

# Function to assign colors based on segment type
def color_segment(x):
    color_map = {'Consumer': '#09CDEF', 'Corporate': '#AB09EF', 'Home Office': '#ABCD09'}
    return [color_map.get(i[1].strip().title(), '#000000') for i in x]

# Function to update legend names
def update_legend(fig, names):
    for i, name in enumerate(names):
        fig.data[i].name = name
    return fig

# Create a copy of the dataset
weekday = store.copy()

# Convert 'Order Date' to datetime if not already
weekday['Order Date'] = pd.to_datetime(weekday['Order Date'])

# Extract day names
weekday['Day'] = weekday['Order Date'].dt.day_name()

# Group by Day & Segment and sum numeric values
weekday = weekday.groupby(['Day', 'Segment']).sum(numeric_only=True)

# Sort by Sales for better visualization
weekday = weekday.sort_values(by='Sales')

# Create scatter plot
fig = px.scatter(
    weekday,
    x="Profit",
    y="Sales",
    size="Shipping Cost",
    color=color_segment(weekday.index),
    hover_name=day_segment(weekday.index),
    log_x=True,
    size_max=60,
    title="Sales vs Profit by Day and Segment",
    labels={"Sales": "Total Sales", "Profit": "Total Profit"}
)

"""Observations

Consumer segment purchases more than corporate and home office and is really profitable

Home Office segment is least profitable
"""

import plotly.express as px

# Create a bar chart to visualize sales by sub-category
fig = px.bar(
    categ_sales,
    x=categ_sales.index,
    y="Sales",
    title="Total Sales by Sub-Category",
    labels={"x": "Sub-Category", "y": "Sales"},
    color="Sales",
    color_continuous_scale=px.colors.sequential.Viridis
)

fig.show()

import plotly.express as px

# Ensure categ_sales only contains numeric columns
categ_sales = store.groupby('Sub-Category').sum(numeric_only=True)

# Create scatter plot
fig = px.scatter(
    categ_sales,
    x="Sales",
    y="Profit",
    size="Shipping Cost",
    color="Discount",
    hover_name=categ_sales.index,
    log_x=True,
    size_max=60,
    title="Sales vs Profit by Sub-Category"
)

fig.show()

"""Observations

Copier are 2nd highest selling Sub-Category but makes most of the profit

Tables generate loss in general
"""

import plotly.express as px

# Ensure country_profit only contains numeric columns
country_profit = store.groupby('Country').sum(numeric_only=True)

# Create a geographical scatter plot
fig = px.scatter_geo(
    country_profit,
    locations=country_profit.index,
    hover_name=country_profit.index,
    locationmode='country names',
    size=country_profit["Quantity"],
    color=country_profit["Quantity"],
    projection='orthographic',
    title="Quantity Distribution by Country"
)

fig.show()

"""Observations

Highest average quantity bought is from slovenia
"""

fig = px.choropleth(country_profit, color="Sales",locationmode='country names',
                    locations=country_profit.index,)
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()

"""Observations

Except Chad, most of the countries make sales less than 400K

# Training and Testing Set
"""

#Dropping unnecessary columns
drop=['Row ID','Order ID','Order Date','Ship Date',
      'Customer ID','Customer Name','Postal Code','Product ID',
     'Product Name']
mean_filled_data.drop(drop,axis=1,inplace=True)

from sklearn.model_selection import train_test_split

# Separate features (X) and target variable (y)
mX = mean_filled_data.drop('Sales', axis=1)
my = mean_filled_data["Sales"]

# Split into training and testing sets
mX_train, mX_test, my_train, my_test = train_test_split(
    mX, my, test_size=0.3, random_state=0, shuffle=True
)

# Check the shape of the resulting datasets
print(f"Training set: {mX_train.shape}, {my_train.shape}")
print(f"Testing set: {mX_test.shape}, {my_test.shape}")

zero_filled_data.drop(drop,axis=1,inplace=True)

zX = zero_filled_data.drop('Sales', axis = 1)
zy = zero_filled_data.Sales
zX_train, zX_test, zy_train, zy_test = train_test_split(zX, zy, random_state = 0, test_size=0.3)

"""# Encoding Ctegorical Data"""

dummy=['Ship Mode','Segment','City','State','Country','Market',
       'Region','Category','Sub-Category','Quantity','Order Priority']

mX_train=pd.get_dummies(mX_train,columns=dummy)
zX_train=pd.get_dummies(zX_train, columns=dummy)
mX_test=pd.get_dummies(mX_test, columns=dummy)
zX_test=pd.get_dummies(zX_test, columns=dummy)

print('Shape of mean train data: ',mX_train.shape)
print('Shape of mean test data: ',mX_test.shape)
print('Shape of zero train data: ',zX_train.shape)
print('Shape of zero test data: ',zX_test.shape)

"""# Training Model"""

from sklearn.linear_model import LinearRegression

mean_lr=LinearRegression()
mean_lr.fit(mX_train,my_train)

zero_lr=LinearRegression()
zero_lr.fit(zX_train,zy_train)

"""# Evaluating the Models"""

# Metrics we will be using R2, RMSE, MSE, MAE
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error

import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Initialize the evaluation dictionary
def initialize_evaluator():
    return {'Model': [], 'R2': [], 'MAE': [], 'MSE': [], 'RMSE': []}

# Insert data into the evaluation dictionary
def insert_data(test, pred, model, eval_data=None):
    if eval_data is None:
        eval_data = initialize_evaluator()

    eval_data['Model'].append(model)
    eval_data['R2'].append(r2_score(test, pred))
    eval_data['MAE'].append(mean_absolute_error(test, pred))
    eval_data['MSE'].append(mean_squared_error(test, pred))
    eval_data['RMSE'].append(np.sqrt(mean_squared_error(test, pred)))  # RMSE is always positive

    return eval_data

# Append data from one dictionary to another
def append_data(data1, data2):
    for key in data1.keys():
        data2[key].extend(data1[key])
    return data2

eval_data = insert_data(my_test, mean_lr.predict(mX_test), 'Mean Linear Regression')
zero_evl_data = insert_data(zy_test, zero_lr.predict(zX_test), 'Zero Linear Regression')

# Append Zero Linear Regression results to Mean Linear Regression results
eval_data = append_data(zero_evl_data, eval_data)

pd.DataFrame(eval_data)